{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 앙상블\n",
    "- 여러개의 분류모델을 조합해서 더 나은 성능을 내는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest\n",
    ": 의사결정트리 bagging(단일 모델 조합)해서 예측을 실행하는 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손글씨 데이터 \n",
    "mnist = datasets.load_digits()\n",
    "features, labels = mnist.data, mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각각의 정답률 :  [0.8280229671011794, 0.8235630043451273, 0.8224674115456239, 0.8235692116697703, 0.8341464928615766, 0.8185692116697704, 0.8241247672253259, 0.8180136561142148, 0.8235630043451272, 0.8258038485412786]\n"
     ]
    }
   ],
   "source": [
    "# 의사결정 나무를 이용한 교차 검증 10번 실시\n",
    "from sklearn import tree, model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = []\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "for i in range(1,11):\n",
    "  cv_scores.append(model_selection.cross_val_score(clf, features, labels, cv=10).mean())\n",
    "\n",
    "print('각각의 정답률 : ', cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각각의 정답률 :  [0.9526939788950962, 0.9487957790192427, 0.9510211049037863, 0.9549286157666046, 0.9471322160148976, 0.9487988826815641, 0.952122905027933, 0.9454531346989447, 0.9460180012414648, 0.9471322160148976]\n"
     ]
    }
   ],
   "source": [
    "# RandomForest를 이용한 교차 검증 10번 실시\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cv_scores = []\n",
    "\n",
    "\n",
    "for i in range(1,11):\n",
    "  scores = cross_val_score(\n",
    "    RandomForestClassifier(),\n",
    "    features,\n",
    "    labels,\n",
    "    cv=10,\n",
    "    scoring='accuracy'\n",
    "  )\n",
    "  cv_scores.append(scores.mean())\n",
    "\n",
    "print('각각의 정답률 : ', cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(classifier,features,labels):\n",
    "    cv_scores=[]\n",
    "    for i in range(0,10):\n",
    "        score1 = cross_val_score(classifier,features,labels,cv=10,scoring='accuracy')\n",
    "        cv_scores.append(score1.mean())\n",
    "    return cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8330509000620733,\n",
       " 0.8224736188702669,\n",
       " 0.8268963376784605,\n",
       " 0.8246710117939168,\n",
       " 0.825788330229671,\n",
       " 0.821880819366853,\n",
       " 0.833584729981378,\n",
       " 0.8280167597765363,\n",
       " 0.826340782122905,\n",
       " 0.8235816263190564]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 의사결정 나무 \n",
    "dt_cv_scores = cross_validation(tree.DecisionTreeClassifier(),features,labels)\n",
    "dt_cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9504655493482307,\n",
       " 0.9410117939168219,\n",
       " 0.9510211049037863,\n",
       " 0.9549162011173185,\n",
       " 0.9504469273743016,\n",
       " 0.9449130974549969,\n",
       " 0.9510117939168218,\n",
       " 0.9493513345747981,\n",
       " 0.9488081936685286,\n",
       " 0.9471198013656114]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForest \n",
    "rf_cv_scores = cross_validation(RandomForestClassifier(),features,labels)\n",
    "rf_cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랜덤포레스트와 의사결정나무의 정확도의 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "cv_list = {'random_forest' : rf_cv_scores, 'decision_tree' : dt_cv_scores}\n",
    "df = pd.DataFrame(cv_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 보팅(voting)앙상블\n",
    ": 단일 모델을 앙상블하여 더 나은 예측을 하는 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단일 모델 정확도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_tree : 0.8805555555555555\n"
     ]
    }
   ],
   "source": [
    "# 의사결정 나무\n",
    "dtree = tree.DecisionTreeClassifier()\n",
    "dtree = dtree.fit(X_train, y_train)\n",
    "dtree_score = dtree.score(X_test, y_test)\n",
    "print(\"d_tree :\", dtree_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knn : 0.9805555555555555\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier().fit(X_train, y_train)\n",
    "knn_score = knn.score(X_test, y_test)\n",
    "print(\"Knn :\", knn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM : 0.9861111111111112\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(probability=True).fit(X_train, y_train)\n",
    "svm_score = svm.score(X_test, y_test)\n",
    "print(\"SVM :\", svm_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하드 보팅\n",
    ": 각각의 분류기의 예측값들을 모아, 가장 많은 득표를 받은 예측값으로 최종 결론을 내는 방식 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9861111111111112"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_clf = VotingClassifier(\n",
    "  estimators=[('decision_tree', dtree),('knn', knn), ('svm', svm)],\n",
    "  weights=[1,1,1], # 가중치\n",
    "  voting='hard'\n",
    "\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "voting_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 소프트 보팅\n",
    ": 각각의 분류모델을 활용하여 모든 분류값들의 확률들을 더해서 가장 높은 점수를 획득한 분류값으로 최종결론을 내는 방식입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9833333333333333"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_clf = VotingClassifier(\n",
    "  estimators=[('decision_tree', dtree),('knn', knn), ('svm', svm)],\n",
    "  weights=[1,1,1], # 가중치\n",
    "  voting='soft'\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "voting_clf.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c34e8390e776d2ee205b71ed5a6130fee3cef8da5e87e926ce18e14f4a070d72"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
